{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "import pandas as pd\n",
    "\n",
    "doc=docx.Document('VocabDrilling.docx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc.paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com=[]\n",
    "for paragraph in doc.paragraphs:\n",
    "    com.append(paragraph.text)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    " \n",
    " \n",
    "USER_AGENT = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36'}\n",
    " \n",
    " \n",
    "def fetch_results(search_term, number_results, language_code):\n",
    "    assert isinstance(search_term, str), 'Search term must be a string'\n",
    "    assert isinstance(number_results, int), 'Number of results must be an integer'\n",
    "    escaped_search_term = search_term.replace(' ', '+')\n",
    " \n",
    "    google_url = 'https://www.google.com/search?q={}&num={}&hl={}'.format(escaped_search_term, number_results, language_code)\n",
    "    response = requests.get(google_url, headers=USER_AGENT)\n",
    "    response.raise_for_status()\n",
    " \n",
    "    return search_term, response.text\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    keyword, html = fetch_results('edmund martin', 100, 'en')\n",
    "    print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_results(html, keyword):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    " \n",
    "    found_results = []\n",
    "    rank = 1\n",
    "    result_block = soup.find_all('div', attrs={'class': 'g'})\n",
    "    for result in result_block:\n",
    " \n",
    "        link = result.find('a', href=True)\n",
    "        title = result.find('h3')\n",
    "        description = result.find('span', attrs={'class': 'st'})\n",
    "        if link and title:\n",
    "            link = link['href']\n",
    "            title = title.get_text()\n",
    "            if description:\n",
    "                description = description.get_text()\n",
    "            if link != '#':\n",
    "                found_results.append({'keyword': keyword, 'description': description})\n",
    "                \n",
    "    return found_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_google(search_term, number_results, language_code):\n",
    "    try:\n",
    "        keyword, html = fetch_results(search_term, number_results, language_code)\n",
    "        results = parse_results(html, keyword)\n",
    "        return results\n",
    "    except AssertionError:\n",
    "        raise Exception(\"Incorrect arguments parsed to function\")\n",
    "    except requests.HTTPError:\n",
    "        raise Exception(\"You appear to have been blocked by Google\")\n",
    "    except requests.RequestException:\n",
    "        raise Exception(\"Appears to be an issue with your connection\")\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    keywords = com\n",
    "    data = []\n",
    "    for keyword in keywords:\n",
    "            results = scrape_google(keyword, 1, \"en\")\n",
    "            for result in results:\n",
    "                data.append(result)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "\n",
    "document = Document()\n",
    "document.add_heading('Vocab Drilling', 0)\n",
    "\n",
    "recordset = data\n",
    "p.add_run('bold').bold = True\n",
    "table = document.add_table(rows=1, cols=2)\n",
    "hdr_cells = table.rows[0].cells\n",
    "hdr_cells[0].text = 'keyword'\n",
    "hdr_cells[1].text = 'Description'\n",
    "for item in recordset:\n",
    "\t#print(item)\n",
    "\trow_cells = table.add_row().cells\n",
    "\trow_cells[0].text = str(item['keyword'])\n",
    "\trow_cells[1].text = str(item['description'])\n",
    "\n",
    "\n",
    "document.add_page_break()\n",
    "\n",
    "document.save('simple.docx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}